{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NPAN6jGEYv_c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from scipy.stats import skew\n",
        "from sklearn.linear_model import LinearRegression, Ridge, LassoCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "#from xgboost.sklearn import XGBRegressor\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from numpy import absolute\n",
        "#import graphviz\n",
        "#import xgboost as xgb\n",
        "from sklearn.preprocessing import (\n",
        "MinMaxScaler,\n",
        "StandardScaler,\n",
        ")\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VoyOdf3cY1FL"
      },
      "outputs": [],
      "source": [
        "df_august = pd.read_csv('https://raw.githubusercontent.com/WitoldSurdej/PFML/master/apartments_pl_2023_08.csv')\n",
        "df_september = pd.read_csv('https://raw.githubusercontent.com/WitoldSurdej/PFML/master/apartments_pl_2023_09.csv')\n",
        "df_october = pd.read_csv('https://raw.githubusercontent.com/WitoldSurdej/PFML/master/apartments_pl_2023_10.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UIOAgyvUZAix"
      },
      "outputs": [],
      "source": [
        "df_august['Month'] = 0\n",
        "df_september['Month'] = 1\n",
        "df_october['Month'] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L_r0VL46ZGRZ"
      },
      "outputs": [],
      "source": [
        "frames = [df_august, df_september, df_october]\n",
        "df = pd.concat(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctNBgcOvZKaE",
        "outputId": "50dee212-ba51-4a1f-9b05-79445fbf1fa1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(52592, 29)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shape of dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c0QMFsD9ZN6f"
      },
      "outputs": [],
      "source": [
        "# Dropping id and columns which have a very high number of missing values, being impossible to apply techniques such as imputation\n",
        "df.drop(['id','type', 'floor', 'buildYear', 'floorCount', 'condition', 'buildingMaterial','Month'], axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZClRGV6paMOF"
      },
      "outputs": [],
      "source": [
        "num_cols = df.select_dtypes([np.number]).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OrFDZ5uaTNj",
        "outputId": "7681c10a-80be-47d4-9216-a2d417203d78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(52592, 14)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_nums = df[num_cols].reset_index(drop=True)\n",
        "df_nums.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vYwrr6GcZbxR"
      },
      "outputs": [],
      "source": [
        "# Dropping rows which contain missing values\n",
        "df_clean = df_nums.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kimPHcngZcYv"
      },
      "outputs": [],
      "source": [
        "# Dropping duplicates if any\n",
        "df_clean = df_clean.drop_duplicates().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAMU_0ugZe2r",
        "outputId": "9cfa8947-5f19-43aa-decd-5069fd46d02b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32038, 14)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_clean.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dyxCzPoOZk0J"
      },
      "outputs": [],
      "source": [
        "cat_cols = df_clean.select_dtypes(['object']).columns\n",
        "df_cats = df_clean[cat_cols].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "K8ULD6tUZ9rU",
        "outputId": "1e1c54b4-521b-4687-9ccc-66b574eb3f74"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>squareMeters</th>\n",
              "      <th>rooms</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>centreDistance</th>\n",
              "      <th>poiCount</th>\n",
              "      <th>schoolDistance</th>\n",
              "      <th>clinicDistance</th>\n",
              "      <th>postOfficeDistance</th>\n",
              "      <th>kindergartenDistance</th>\n",
              "      <th>restaurantDistance</th>\n",
              "      <th>collegeDistance</th>\n",
              "      <th>pharmacyDistance</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>53.442692</td>\n",
              "      <td>14.559690</td>\n",
              "      <td>2.15</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.273</td>\n",
              "      <td>0.492</td>\n",
              "      <td>0.652</td>\n",
              "      <td>0.291</td>\n",
              "      <td>0.348</td>\n",
              "      <td>1.404</td>\n",
              "      <td>0.205</td>\n",
              "      <td>395995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>73.02</td>\n",
              "      <td>3.0</td>\n",
              "      <td>53.452222</td>\n",
              "      <td>14.553333</td>\n",
              "      <td>3.24</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.275</td>\n",
              "      <td>0.672</td>\n",
              "      <td>0.367</td>\n",
              "      <td>0.246</td>\n",
              "      <td>0.300</td>\n",
              "      <td>1.857</td>\n",
              "      <td>0.280</td>\n",
              "      <td>565000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>87.60</td>\n",
              "      <td>3.0</td>\n",
              "      <td>53.435100</td>\n",
              "      <td>14.532900</td>\n",
              "      <td>2.27</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.175</td>\n",
              "      <td>0.259</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.359</td>\n",
              "      <td>0.101</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.087</td>\n",
              "      <td>640000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>66.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>53.410278</td>\n",
              "      <td>14.503611</td>\n",
              "      <td>4.07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.218</td>\n",
              "      <td>1.690</td>\n",
              "      <td>0.504</td>\n",
              "      <td>0.704</td>\n",
              "      <td>0.501</td>\n",
              "      <td>2.138</td>\n",
              "      <td>0.514</td>\n",
              "      <td>759000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63.30</td>\n",
              "      <td>3.0</td>\n",
              "      <td>53.463100</td>\n",
              "      <td>14.572800</td>\n",
              "      <td>4.48</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.079</td>\n",
              "      <td>1.224</td>\n",
              "      <td>0.737</td>\n",
              "      <td>0.260</td>\n",
              "      <td>1.102</td>\n",
              "      <td>0.377</td>\n",
              "      <td>0.745</td>\n",
              "      <td>499000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   squareMeters  rooms   latitude  ...  collegeDistance  pharmacyDistance   price\n",
              "0         36.00    2.0  53.442692  ...            1.404             0.205  395995\n",
              "1         73.02    3.0  53.452222  ...            1.857             0.280  565000\n",
              "2         87.60    3.0  53.435100  ...            0.310             0.087  640000\n",
              "3         66.00    3.0  53.410278  ...            2.138             0.514  759000\n",
              "4         63.30    3.0  53.463100  ...            0.377             0.745  499000\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "B34yp4s_ajFz",
        "outputId": "a0431a08-a4ce-4124-fa6c-a024a5d18e53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>squareMeters</th>\n",
              "      <th>rooms</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>centreDistance</th>\n",
              "      <th>poiCount</th>\n",
              "      <th>schoolDistance</th>\n",
              "      <th>clinicDistance</th>\n",
              "      <th>postOfficeDistance</th>\n",
              "      <th>kindergartenDistance</th>\n",
              "      <th>restaurantDistance</th>\n",
              "      <th>collegeDistance</th>\n",
              "      <th>pharmacyDistance</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>32038.000000</td>\n",
              "      <td>3.203800e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>57.149583</td>\n",
              "      <td>2.625258</td>\n",
              "      <td>51.985320</td>\n",
              "      <td>19.562597</td>\n",
              "      <td>4.330976</td>\n",
              "      <td>20.078969</td>\n",
              "      <td>0.387949</td>\n",
              "      <td>0.951657</td>\n",
              "      <td>0.489389</td>\n",
              "      <td>0.339536</td>\n",
              "      <td>0.329925</td>\n",
              "      <td>1.473548</td>\n",
              "      <td>0.335175</td>\n",
              "      <td>6.942392e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.387076</td>\n",
              "      <td>0.888286</td>\n",
              "      <td>1.309210</td>\n",
              "      <td>1.755493</td>\n",
              "      <td>2.768399</td>\n",
              "      <td>22.763925</td>\n",
              "      <td>0.383238</td>\n",
              "      <td>0.849242</td>\n",
              "      <td>0.415407</td>\n",
              "      <td>0.352139</td>\n",
              "      <td>0.377508</td>\n",
              "      <td>1.108303</td>\n",
              "      <td>0.369143</td>\n",
              "      <td>3.407004e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>25.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>49.981357</td>\n",
              "      <td>14.462282</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>1.500000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>43.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>51.108744</td>\n",
              "      <td>18.546066</td>\n",
              "      <td>2.090000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>0.236000</td>\n",
              "      <td>0.154000</td>\n",
              "      <td>0.117000</td>\n",
              "      <td>0.599000</td>\n",
              "      <td>0.144000</td>\n",
              "      <td>4.600000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>53.310000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>52.190000</td>\n",
              "      <td>19.924150</td>\n",
              "      <td>3.980000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.286000</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>0.386000</td>\n",
              "      <td>0.258000</td>\n",
              "      <td>0.233000</td>\n",
              "      <td>1.150000</td>\n",
              "      <td>0.237000</td>\n",
              "      <td>6.290000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>66.400000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>52.389519</td>\n",
              "      <td>20.996740</td>\n",
              "      <td>6.020000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.453000</td>\n",
              "      <td>1.226750</td>\n",
              "      <td>0.611000</td>\n",
              "      <td>0.405000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>2.107000</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>8.300000e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>54.571600</td>\n",
              "      <td>23.207128</td>\n",
              "      <td>16.940000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>4.472000</td>\n",
              "      <td>4.996000</td>\n",
              "      <td>4.585000</td>\n",
              "      <td>4.680000</td>\n",
              "      <td>4.269000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.242000</td>\n",
              "      <td>2.500000e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       squareMeters         rooms  ...  pharmacyDistance         price\n",
              "count  32038.000000  32038.000000  ...      32038.000000  3.203800e+04\n",
              "mean      57.149583      2.625258  ...          0.335175  6.942392e+05\n",
              "std       20.387076      0.888286  ...          0.369143  3.407004e+05\n",
              "min       25.000000      1.000000  ...          0.001000  1.500000e+05\n",
              "25%       43.000000      2.000000  ...          0.144000  4.600000e+05\n",
              "50%       53.310000      3.000000  ...          0.237000  6.290000e+05\n",
              "75%       66.400000      3.000000  ...          0.396000  8.300000e+05\n",
              "max      150.000000      6.000000  ...          4.242000  2.500000e+06\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_clean.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5q_8Zk9tlJZ",
        "outputId": "6ecc1e3c-054c-4631-d3ef-a7b2ec734a98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['squareMeters', 'rooms', 'latitude', 'longitude', 'centreDistance',\n",
            "       'poiCount', 'schoolDistance', 'clinicDistance', 'postOfficeDistance',\n",
            "       'kindergartenDistance', 'restaurantDistance', 'collegeDistance',\n",
            "       'pharmacyDistance', 'price'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df_clean.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOR5L7bhZzZR"
      },
      "source": [
        "DATA SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5ovcwqztZpyD"
      },
      "outputs": [],
      "source": [
        "\n",
        "#X1 = df_clean.loc[:,df_clean.columns != 'price']\n",
        "#X1 = df_clean.loc[:,df_clean.columns == ['squareMeters','longitude','poiCount']]\n",
        "selected_columns=['squareMeters', 'longitude', 'poiCount']\n",
        "X1 = df_clean[selected_columns]\n",
        "y1 = df_clean['price'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mM8ga4Qzp9nP"
      },
      "outputs": [],
      "source": [
        "minmax_scaler = MinMaxScaler().set_output(transform=\"pandas\")\n",
        "X1_normalized = minmax_scaler.fit_transform(X1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RP05a4WpZx7x"
      },
      "outputs": [],
      "source": [
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1_normalized, y1, test_size = 0.3, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiAX7Q6dcWAa",
        "outputId": "aa7d612a-17ae-4ccf-e58d-5d1d86857fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32038, 3)\n",
            "(32038,)\n",
            "(22426, 3)\n",
            "(22426,)\n",
            "(9612, 3)\n",
            "(9612,)\n"
          ]
        }
      ],
      "source": [
        "print(X1_normalized.shape)\n",
        "print(y1.shape)\n",
        "print(X1_train.shape)\n",
        "print(y1_train.shape)\n",
        "print(X1_test.shape)\n",
        "print(y1_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mLHZt-vHC-M",
        "outputId": "6b211017-4cdf-4ed9-ab26-1a2ce0cdb4ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(22426, 3)\n",
            "(22426,)\n",
            "(15698, 3)\n",
            "(15698,)\n",
            "(6728, 3)\n",
            "(6728,)\n"
          ]
        }
      ],
      "source": [
        "X1_train1, X1_validation, y1_train1, y1_validation = train_test_split(X1_train, y1_train, test_size = 0.3, random_state = 41)\n",
        "print(X1_train.shape)\n",
        "print(y1_train.shape)\n",
        "print(X1_train1.shape)\n",
        "print(y1_train1.shape)\n",
        "print(X1_validation.shape)\n",
        "print(y1_validation.shape)\n",
        "#X1_train1.to_csv('data.csv', index=False)\n",
        "#y1_train1.to_csv('data.csv', index=False) \n",
        "#X1_validation.to_csv('data.csv', index=False) \n",
        "#y1_validation.to_csv('data.csv', index=False) \n",
        "#X1_test.to_csv('data.csv', index=False) \n",
        "#y1_test.to_csv('data.csv', index=False) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_NN(X1_train1,y1_train1,X1_validation,y1_validation,model,num_iterations):\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    #accuracy_train=np.zeros([1,num_iterations])\n",
        "    #accuracy_validation=np.zeros([1,num_iterations])\n",
        "    #accuracy_test=np.zeros([1,num_iterations])\n",
        "\n",
        "    #accuracy=np.zeros([3,num_iterations])\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "\n",
        "        # Define a callback to collect training history\n",
        "        history_callback = tf.keras.callbacks.History()\n",
        "\n",
        "        early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',  # Monitor validation loss\n",
        "        patience=5,  # Stop training if no improvement for 5 consecutive epochs\n",
        "        restore_best_weights=True  # Restore model weights to the best observed during training\n",
        "        )\n",
        "\n",
        "        history = model.fit(X1_train1, y1_train1, epochs=500, validation_data=(X1_validation, y1_validation), callbacks=[early_stopping_callback])\n",
        "\n",
        "    return history, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MUhD7r0UdquA",
        "outputId": "c7bfcd5c-f5b0-451f-84c3-f9df7d272c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "491/491 [==============================] - 2s 3ms/step - loss: 2573036.7500 - accuracy: 0.0000e+00 - val_loss: 532939.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -721531.7500 - accuracy: 0.0000e+00 - val_loss: -4943470.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "491/491 [==============================] - 1s 3ms/step - loss: -8024369.5000 - accuracy: 0.0000e+00 - val_loss: -8895570.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "491/491 [==============================] - 2s 3ms/step - loss: -9175206.0000 - accuracy: 0.0000e+00 - val_loss: -9484550.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "491/491 [==============================] - 2s 3ms/step - loss: -10057196.0000 - accuracy: 0.0000e+00 - val_loss: -10190503.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -10335462.0000 - accuracy: 0.0000e+00 - val_loss: -10345077.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -10413968.0000 - accuracy: 0.0000e+00 - val_loss: -10367520.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "491/491 [==============================] - 2s 3ms/step - loss: -10430024.0000 - accuracy: 0.0000e+00 - val_loss: -10381990.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "491/491 [==============================] - 2s 4ms/step - loss: -10434286.0000 - accuracy: 0.0000e+00 - val_loss: -10385458.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -10436093.0000 - accuracy: 0.0000e+00 - val_loss: -10386688.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -10438287.0000 - accuracy: 0.0000e+00 - val_loss: -10389430.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -10441933.0000 - accuracy: 0.0000e+00 - val_loss: -10391100.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "491/491 [==============================] - 1s 3ms/step - loss: -10443207.0000 - accuracy: 0.0000e+00 - val_loss: -10392753.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "491/491 [==============================] - 1s 3ms/step - loss: -10445189.0000 - accuracy: 0.0000e+00 - val_loss: -10395565.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "491/491 [==============================] - 2s 3ms/step - loss: -10449913.0000 - accuracy: 0.0000e+00 - val_loss: -10409183.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -10521591.0000 - accuracy: 0.0000e+00 - val_loss: -10564069.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -10605896.0000 - accuracy: 0.0000e+00 - val_loss: -10564490.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -10606823.0000 - accuracy: 0.0000e+00 - val_loss: -10565699.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -10606858.0000 - accuracy: 0.0000e+00 - val_loss: -10569088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "491/491 [==============================] - 1s 3ms/step - loss: -10607462.0000 - accuracy: 0.0000e+00 - val_loss: -10569088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "491/491 [==============================] - 1s 3ms/step - loss: -10607464.0000 - accuracy: 0.0000e+00 - val_loss: -10569088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "491/491 [==============================] - 1s 3ms/step - loss: -10607459.0000 - accuracy: 0.0000e+00 - val_loss: -10569088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "491/491 [==============================] - 1s 3ms/step - loss: -10607455.0000 - accuracy: 0.0000e+00 - val_loss: -10569088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "491/491 [==============================] - 1s 3ms/step - loss: -10607461.0000 - accuracy: 0.0000e+00 - val_loss: -10569088.0000 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(3,)),  # Input layer with 2 features\n",
        "#    tf.keras.layers.Dense(3, activation='sigmoid'),  # Hidden layer with 4 neurons and ReLU activation\n",
        "#    tf.keras.layers.Dense(3, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(1, activation='relu')  # Output layer with sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "\n",
        "num_iterations=1\n",
        "\n",
        "\n",
        "history, model = train_NN(X1_train1,y1_train1,X1_validation,y1_validation,model,num_iterations)\n",
        "\n",
        "\n",
        "  #history = model.fit(X1_train1, y1_train1, epochs=50, batch_size=32, callbacks=[history_callback])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Extract accuracy values from the training history\n",
        "training_accuracy_per_epoch = history.history['loss']\n",
        "validation_accuracy_per_epoch = history.history['val_loss']\n",
        "\n",
        "  #loss_train, accuracy= model.evaluate(X1_train1, y1_train1)\n",
        "  #loss_train, accuracy= model.evaluate(X1_train, y1_train)\n",
        "\n",
        "  \n",
        "  # Plot the accuracy values\n",
        "plt.plot(training_accuracy_per_epoch, label='Training Accuracy')\n",
        "plt.plot(validation_accuracy_per_epoch, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -268196.1562 - accuracy: 0.0000e+00 - val_loss: -608060.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -951330.7500 - accuracy: 0.0000e+00 - val_loss: -1288022.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -1634571.8750 - accuracy: 0.0000e+00 - val_loss: -1968705.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/500\n",
            "491/491 [==============================] - 0s 964us/step - loss: -2318349.0000 - accuracy: 0.0000e+00 - val_loss: -2649644.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -3001941.5000 - accuracy: 0.0000e+00 - val_loss: -3330327.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -3685123.7500 - accuracy: 0.0000e+00 - val_loss: -4011025.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/500\n",
            "491/491 [==============================] - 0s 997us/step - loss: -4368730.0000 - accuracy: 0.0000e+00 - val_loss: -4691561.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -5052449.0000 - accuracy: 0.0000e+00 - val_loss: -5371741.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -5735901.0000 - accuracy: 0.0000e+00 - val_loss: -6053242.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -6419236.0000 - accuracy: 0.0000e+00 - val_loss: -6733102.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -7102696.5000 - accuracy: 0.0000e+00 - val_loss: -7414173.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -7786217.5000 - accuracy: 0.0000e+00 - val_loss: -8095395.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -8469293.0000 - accuracy: 0.0000e+00 - val_loss: -8774458.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -9152334.0000 - accuracy: 0.0000e+00 - val_loss: -9455104.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -9835283.0000 - accuracy: 0.0000e+00 - val_loss: -10134890.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -10518016.0000 - accuracy: 0.0000e+00 - val_loss: -10814705.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -11201218.0000 - accuracy: 0.0000e+00 - val_loss: -11495924.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/500\n",
            "491/491 [==============================] - 0s 997us/step - loss: -11885019.0000 - accuracy: 0.0000e+00 - val_loss: -12176535.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -12568525.0000 - accuracy: 0.0000e+00 - val_loss: -12857651.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -13252191.0000 - accuracy: 0.0000e+00 - val_loss: -13538060.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -13935578.0000 - accuracy: 0.0000e+00 - val_loss: -14218335.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/500\n",
            "491/491 [==============================] - 0s 997us/step - loss: -14619175.0000 - accuracy: 0.0000e+00 - val_loss: -14899693.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -15302757.0000 - accuracy: 0.0000e+00 - val_loss: -15580170.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -15986532.0000 - accuracy: 0.0000e+00 - val_loss: -16261441.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -16669629.0000 - accuracy: 0.0000e+00 - val_loss: -16941764.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -17352658.0000 - accuracy: 0.0000e+00 - val_loss: -17621788.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -18035992.0000 - accuracy: 0.0000e+00 - val_loss: -18302442.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -18719474.0000 - accuracy: 0.0000e+00 - val_loss: -18982432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -19402984.0000 - accuracy: 0.0000e+00 - val_loss: -19663734.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -20086542.0000 - accuracy: 0.0000e+00 - val_loss: -20343860.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -20770034.0000 - accuracy: 0.0000e+00 - val_loss: -21025038.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -21453296.0000 - accuracy: 0.0000e+00 - val_loss: -21705580.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -22136016.0000 - accuracy: 0.0000e+00 - val_loss: -22385500.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -22819190.0000 - accuracy: 0.0000e+00 - val_loss: -23065368.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -23502820.0000 - accuracy: 0.0000e+00 - val_loss: -23746234.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -24185950.0000 - accuracy: 0.0000e+00 - val_loss: -24426660.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -24869522.0000 - accuracy: 0.0000e+00 - val_loss: -25107796.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -25552586.0000 - accuracy: 0.0000e+00 - val_loss: -25787752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -26235784.0000 - accuracy: 0.0000e+00 - val_loss: -26468318.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -26919054.0000 - accuracy: 0.0000e+00 - val_loss: -27148252.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -27602674.0000 - accuracy: 0.0000e+00 - val_loss: -27828962.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -28286092.0000 - accuracy: 0.0000e+00 - val_loss: -28509812.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -28969046.0000 - accuracy: 0.0000e+00 - val_loss: -29190070.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -29651992.0000 - accuracy: 0.0000e+00 - val_loss: -29870228.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -30334818.0000 - accuracy: 0.0000e+00 - val_loss: -30550160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -31018504.0000 - accuracy: 0.0000e+00 - val_loss: -31231482.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -31702084.0000 - accuracy: 0.0000e+00 - val_loss: -31911792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -32385730.0000 - accuracy: 0.0000e+00 - val_loss: -32592614.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -33069170.0000 - accuracy: 0.0000e+00 - val_loss: -33273734.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -33752544.0000 - accuracy: 0.0000e+00 - val_loss: -33954464.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -34435876.0000 - accuracy: 0.0000e+00 - val_loss: -34634860.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -35118844.0000 - accuracy: 0.0000e+00 - val_loss: -35314380.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -35801968.0000 - accuracy: 0.0000e+00 - val_loss: -35995308.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -36485484.0000 - accuracy: 0.0000e+00 - val_loss: -36676016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -37169232.0000 - accuracy: 0.0000e+00 - val_loss: -37356800.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -37852580.0000 - accuracy: 0.0000e+00 - val_loss: -38037364.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -38535724.0000 - accuracy: 0.0000e+00 - val_loss: -38717088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -39218952.0000 - accuracy: 0.0000e+00 - val_loss: -39398044.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -39902304.0000 - accuracy: 0.0000e+00 - val_loss: -40078164.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -40585548.0000 - accuracy: 0.0000e+00 - val_loss: -40758884.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -41269160.0000 - accuracy: 0.0000e+00 - val_loss: -41439840.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -41952760.0000 - accuracy: 0.0000e+00 - val_loss: -42120956.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -42636232.0000 - accuracy: 0.0000e+00 - val_loss: -42801368.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -43319364.0000 - accuracy: 0.0000e+00 - val_loss: -43481684.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -44003148.0000 - accuracy: 0.0000e+00 - val_loss: -44162088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -44686656.0000 - accuracy: 0.0000e+00 - val_loss: -44843344.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/500\n",
            "491/491 [==============================] - 0s 997us/step - loss: -45370056.0000 - accuracy: 0.0000e+00 - val_loss: -45522824.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -46053620.0000 - accuracy: 0.0000e+00 - val_loss: -46204428.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -46736712.0000 - accuracy: 0.0000e+00 - val_loss: -46884764.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -47419704.0000 - accuracy: 0.0000e+00 - val_loss: -47564928.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -48102836.0000 - accuracy: 0.0000e+00 - val_loss: -48245144.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -48786504.0000 - accuracy: 0.0000e+00 - val_loss: -48926524.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -49470144.0000 - accuracy: 0.0000e+00 - val_loss: -49606792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/500\n",
            "491/491 [==============================] - 0s 998us/step - loss: -50153508.0000 - accuracy: 0.0000e+00 - val_loss: -50287176.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -50837144.0000 - accuracy: 0.0000e+00 - val_loss: -50968136.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -51520768.0000 - accuracy: 0.0000e+00 - val_loss: -51648964.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -52204160.0000 - accuracy: 0.0000e+00 - val_loss: -52329256.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/500\n",
            "491/491 [==============================] - 0s 988us/step - loss: -52886884.0000 - accuracy: 0.0000e+00 - val_loss: -53009244.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -53569640.0000 - accuracy: 0.0000e+00 - val_loss: -53689448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -54252988.0000 - accuracy: 0.0000e+00 - val_loss: -54369960.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -54936464.0000 - accuracy: 0.0000e+00 - val_loss: -55050984.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -55619880.0000 - accuracy: 0.0000e+00 - val_loss: -55731364.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -56303748.0000 - accuracy: 0.0000e+00 - val_loss: -56412208.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/500\n",
            "491/491 [==============================] - 0s 992us/step - loss: -56987392.0000 - accuracy: 0.0000e+00 - val_loss: -57093336.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -57671260.0000 - accuracy: 0.0000e+00 - val_loss: -57774528.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -58354820.0000 - accuracy: 0.0000e+00 - val_loss: -58454448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -59037972.0000 - accuracy: 0.0000e+00 - val_loss: -59134752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/500\n",
            "491/491 [==============================] - 0s 958us/step - loss: -59721204.0000 - accuracy: 0.0000e+00 - val_loss: -59815592.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -60404300.0000 - accuracy: 0.0000e+00 - val_loss: -60495856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -61087524.0000 - accuracy: 0.0000e+00 - val_loss: -61176176.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -61771384.0000 - accuracy: 0.0000e+00 - val_loss: -61857456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -62455220.0000 - accuracy: 0.0000e+00 - val_loss: -62537792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -63138900.0000 - accuracy: 0.0000e+00 - val_loss: -63218932.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/500\n",
            "491/491 [==============================] - 0s 989us/step - loss: -63822528.0000 - accuracy: 0.0000e+00 - val_loss: -63899800.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/500\n",
            "491/491 [==============================] - 0s 999us/step - loss: -64505736.0000 - accuracy: 0.0000e+00 - val_loss: -64580764.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -65189184.0000 - accuracy: 0.0000e+00 - val_loss: -65260716.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -65873008.0000 - accuracy: 0.0000e+00 - val_loss: -65942296.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -66556844.0000 - accuracy: 0.0000e+00 - val_loss: -66623164.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -67240592.0000 - accuracy: 0.0000e+00 - val_loss: -67303336.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -67923704.0000 - accuracy: 0.0000e+00 - val_loss: -67984064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -68607224.0000 - accuracy: 0.0000e+00 - val_loss: -68664912.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -69290672.0000 - accuracy: 0.0000e+00 - val_loss: -69345600.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -69973736.0000 - accuracy: 0.0000e+00 - val_loss: -70025480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -70657112.0000 - accuracy: 0.0000e+00 - val_loss: -70705896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/500\n",
            "491/491 [==============================] - 0s 998us/step - loss: -71340816.0000 - accuracy: 0.0000e+00 - val_loss: -71387264.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/500\n",
            "491/491 [==============================] - 0s 982us/step - loss: -72024800.0000 - accuracy: 0.0000e+00 - val_loss: -72068520.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -72708280.0000 - accuracy: 0.0000e+00 - val_loss: -72749248.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -73391280.0000 - accuracy: 0.0000e+00 - val_loss: -73428976.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -74074472.0000 - accuracy: 0.0000e+00 - val_loss: -74109672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -74757384.0000 - accuracy: 0.0000e+00 - val_loss: -74789304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -75440288.0000 - accuracy: 0.0000e+00 - val_loss: -75469448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -76123680.0000 - accuracy: 0.0000e+00 - val_loss: -76150424.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -76807376.0000 - accuracy: 0.0000e+00 - val_loss: -76830872.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/500\n",
            "491/491 [==============================] - 0s 999us/step - loss: -77490912.0000 - accuracy: 0.0000e+00 - val_loss: -77511392.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -78174024.0000 - accuracy: 0.0000e+00 - val_loss: -78191952.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -78857448.0000 - accuracy: 0.0000e+00 - val_loss: -78872720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -79540368.0000 - accuracy: 0.0000e+00 - val_loss: -79552512.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -80222776.0000 - accuracy: 0.0000e+00 - val_loss: -80232488.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -80905872.0000 - accuracy: 0.0000e+00 - val_loss: -80912728.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -81589504.0000 - accuracy: 0.0000e+00 - val_loss: -81593640.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/500\n",
            "491/491 [==============================] - 0s 978us/step - loss: -82272920.0000 - accuracy: 0.0000e+00 - val_loss: -82274280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -82956216.0000 - accuracy: 0.0000e+00 - val_loss: -82954864.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -83639248.0000 - accuracy: 0.0000e+00 - val_loss: -83634560.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -84322248.0000 - accuracy: 0.0000e+00 - val_loss: -84315024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -85005824.0000 - accuracy: 0.0000e+00 - val_loss: -84995848.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/500\n",
            "491/491 [==============================] - 0s 957us/step - loss: -85689824.0000 - accuracy: 0.0000e+00 - val_loss: -85677168.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -86373784.0000 - accuracy: 0.0000e+00 - val_loss: -86358128.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -87057792.0000 - accuracy: 0.0000e+00 - val_loss: -87039448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/500\n",
            "491/491 [==============================] - 0s 988us/step - loss: -87741456.0000 - accuracy: 0.0000e+00 - val_loss: -87720352.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -88424872.0000 - accuracy: 0.0000e+00 - val_loss: -88400560.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -89107896.0000 - accuracy: 0.0000e+00 - val_loss: -89080896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -89790712.0000 - accuracy: 0.0000e+00 - val_loss: -89760968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -90473832.0000 - accuracy: 0.0000e+00 - val_loss: -90441568.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -91156904.0000 - accuracy: 0.0000e+00 - val_loss: -91121760.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -91840264.0000 - accuracy: 0.0000e+00 - val_loss: -91801880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -92523944.0000 - accuracy: 0.0000e+00 - val_loss: -92483104.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -93207392.0000 - accuracy: 0.0000e+00 - val_loss: -93163808.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -93890536.0000 - accuracy: 0.0000e+00 - val_loss: -93844024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -94573760.0000 - accuracy: 0.0000e+00 - val_loss: -94524312.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -95257272.0000 - accuracy: 0.0000e+00 - val_loss: -95205128.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -95940728.0000 - accuracy: 0.0000e+00 - val_loss: -95885688.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -96623704.0000 - accuracy: 0.0000e+00 - val_loss: -96565544.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -97307096.0000 - accuracy: 0.0000e+00 - val_loss: -97246424.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -97990680.0000 - accuracy: 0.0000e+00 - val_loss: -97926904.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/500\n",
            "491/491 [==============================] - 0s 991us/step - loss: -98673736.0000 - accuracy: 0.0000e+00 - val_loss: -98607656.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/500\n",
            "491/491 [==============================] - 0s 993us/step - loss: -99357480.0000 - accuracy: 0.0000e+00 - val_loss: -99288456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -100041520.0000 - accuracy: 0.0000e+00 - val_loss: -99969408.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -100724792.0000 - accuracy: 0.0000e+00 - val_loss: -100649728.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -101407688.0000 - accuracy: 0.0000e+00 - val_loss: -101329632.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -102091240.0000 - accuracy: 0.0000e+00 - val_loss: -102010808.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -102774696.0000 - accuracy: 0.0000e+00 - val_loss: -102691552.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -103458104.0000 - accuracy: 0.0000e+00 - val_loss: -103372032.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -104141168.0000 - accuracy: 0.0000e+00 - val_loss: -104052552.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -104824392.0000 - accuracy: 0.0000e+00 - val_loss: -104732792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -105507928.0000 - accuracy: 0.0000e+00 - val_loss: -105413144.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -106191752.0000 - accuracy: 0.0000e+00 - val_loss: -106094160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -106875624.0000 - accuracy: 0.0000e+00 - val_loss: -106775512.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -107558528.0000 - accuracy: 0.0000e+00 - val_loss: -107455288.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -108242368.0000 - accuracy: 0.0000e+00 - val_loss: -108136384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -108926304.0000 - accuracy: 0.0000e+00 - val_loss: -108817928.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -109609408.0000 - accuracy: 0.0000e+00 - val_loss: -109497752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -110292376.0000 - accuracy: 0.0000e+00 - val_loss: -110178008.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -110975960.0000 - accuracy: 0.0000e+00 - val_loss: -110858808.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -111658912.0000 - accuracy: 0.0000e+00 - val_loss: -111538560.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -112342384.0000 - accuracy: 0.0000e+00 - val_loss: -112219672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -113025496.0000 - accuracy: 0.0000e+00 - val_loss: -112899360.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/500\n",
            "491/491 [==============================] - 0s 997us/step - loss: -113708344.0000 - accuracy: 0.0000e+00 - val_loss: -113579608.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -114391616.0000 - accuracy: 0.0000e+00 - val_loss: -114260816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -115075096.0000 - accuracy: 0.0000e+00 - val_loss: -114941336.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -115757904.0000 - accuracy: 0.0000e+00 - val_loss: -115620512.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -116440576.0000 - accuracy: 0.0000e+00 - val_loss: -116300688.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -117123400.0000 - accuracy: 0.0000e+00 - val_loss: -116980880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -117806656.0000 - accuracy: 0.0000e+00 - val_loss: -117661456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -118489848.0000 - accuracy: 0.0000e+00 - val_loss: -118341424.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -119173216.0000 - accuracy: 0.0000e+00 - val_loss: -119022544.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -119856624.0000 - accuracy: 0.0000e+00 - val_loss: -119702472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -120540520.0000 - accuracy: 0.0000e+00 - val_loss: -120383864.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -121224552.0000 - accuracy: 0.0000e+00 - val_loss: -121065800.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -121908200.0000 - accuracy: 0.0000e+00 - val_loss: -121746200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -122591248.0000 - accuracy: 0.0000e+00 - val_loss: -122425856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -123274016.0000 - accuracy: 0.0000e+00 - val_loss: -123105968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -123957448.0000 - accuracy: 0.0000e+00 - val_loss: -123786616.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -124641440.0000 - accuracy: 0.0000e+00 - val_loss: -124467856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -125324976.0000 - accuracy: 0.0000e+00 - val_loss: -125149240.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -126008040.0000 - accuracy: 0.0000e+00 - val_loss: -125829088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -126691744.0000 - accuracy: 0.0000e+00 - val_loss: -126510080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -127375192.0000 - accuracy: 0.0000e+00 - val_loss: -127190304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -128058288.0000 - accuracy: 0.0000e+00 - val_loss: -127870736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -128741584.0000 - accuracy: 0.0000e+00 - val_loss: -128551144.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -129424384.0000 - accuracy: 0.0000e+00 - val_loss: -129231040.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -130107792.0000 - accuracy: 0.0000e+00 - val_loss: -129912048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -130791544.0000 - accuracy: 0.0000e+00 - val_loss: -130592248.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -131474856.0000 - accuracy: 0.0000e+00 - val_loss: -131272160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -132157904.0000 - accuracy: 0.0000e+00 - val_loss: -131952424.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -132840432.0000 - accuracy: 0.0000e+00 - val_loss: -132633040.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -133524376.0000 - accuracy: 0.0000e+00 - val_loss: -133314504.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -134208120.0000 - accuracy: 0.0000e+00 - val_loss: -133995168.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -134890960.0000 - accuracy: 0.0000e+00 - val_loss: -134674800.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -135574368.0000 - accuracy: 0.0000e+00 - val_loss: -135355312.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -136257984.0000 - accuracy: 0.0000e+00 - val_loss: -136036656.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/500\n",
            "491/491 [==============================] - 0s 991us/step - loss: -136941440.0000 - accuracy: 0.0000e+00 - val_loss: -136716912.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -137624192.0000 - accuracy: 0.0000e+00 - val_loss: -137396992.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -138307552.0000 - accuracy: 0.0000e+00 - val_loss: -138078272.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -138990992.0000 - accuracy: 0.0000e+00 - val_loss: -138757904.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -139673712.0000 - accuracy: 0.0000e+00 - val_loss: -139437840.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -140356496.0000 - accuracy: 0.0000e+00 - val_loss: -140117552.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -141039424.0000 - accuracy: 0.0000e+00 - val_loss: -140797840.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -141722912.0000 - accuracy: 0.0000e+00 - val_loss: -141479088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -142406224.0000 - accuracy: 0.0000e+00 - val_loss: -142159424.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -143090160.0000 - accuracy: 0.0000e+00 - val_loss: -142840432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -143773728.0000 - accuracy: 0.0000e+00 - val_loss: -143521424.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -144456400.0000 - accuracy: 0.0000e+00 - val_loss: -144200976.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -145139792.0000 - accuracy: 0.0000e+00 - val_loss: -144882176.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -145823440.0000 - accuracy: 0.0000e+00 - val_loss: -145562544.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -146507104.0000 - accuracy: 0.0000e+00 - val_loss: -146243568.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -147191200.0000 - accuracy: 0.0000e+00 - val_loss: -146924672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -147874880.0000 - accuracy: 0.0000e+00 - val_loss: -147605968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -148558336.0000 - accuracy: 0.0000e+00 - val_loss: -148286048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -149241600.0000 - accuracy: 0.0000e+00 - val_loss: -148966976.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -149924816.0000 - accuracy: 0.0000e+00 - val_loss: -149646544.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -150607600.0000 - accuracy: 0.0000e+00 - val_loss: -150327168.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -151291056.0000 - accuracy: 0.0000e+00 - val_loss: -151007360.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -151974272.0000 - accuracy: 0.0000e+00 - val_loss: -151688192.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -152657728.0000 - accuracy: 0.0000e+00 - val_loss: -152368480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -153340832.0000 - accuracy: 0.0000e+00 - val_loss: -153048304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -154023392.0000 - accuracy: 0.0000e+00 - val_loss: -153729024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -154706624.0000 - accuracy: 0.0000e+00 - val_loss: -154409520.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -155390144.0000 - accuracy: 0.0000e+00 - val_loss: -155089792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -156074016.0000 - accuracy: 0.0000e+00 - val_loss: -155770656.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/500\n",
            "491/491 [==============================] - 1s 2ms/step - loss: -156757664.0000 - accuracy: 0.0000e+00 - val_loss: -156451952.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -157440752.0000 - accuracy: 0.0000e+00 - val_loss: -157131888.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -158123984.0000 - accuracy: 0.0000e+00 - val_loss: -157812544.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -158807520.0000 - accuracy: 0.0000e+00 - val_loss: -158493248.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -159490544.0000 - accuracy: 0.0000e+00 - val_loss: -159173456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -160173744.0000 - accuracy: 0.0000e+00 - val_loss: -159853552.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -160856432.0000 - accuracy: 0.0000e+00 - val_loss: -160533680.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -161539200.0000 - accuracy: 0.0000e+00 - val_loss: -161213632.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -162223008.0000 - accuracy: 0.0000e+00 - val_loss: -161894992.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 239/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -162906416.0000 - accuracy: 0.0000e+00 - val_loss: -162575008.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -163589216.0000 - accuracy: 0.0000e+00 - val_loss: -163254640.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -164271696.0000 - accuracy: 0.0000e+00 - val_loss: -163934976.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -164955072.0000 - accuracy: 0.0000e+00 - val_loss: -164615248.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -165638928.0000 - accuracy: 0.0000e+00 - val_loss: -165296528.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -166323232.0000 - accuracy: 0.0000e+00 - val_loss: -165978544.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -167006704.0000 - accuracy: 0.0000e+00 - val_loss: -166658128.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -167689920.0000 - accuracy: 0.0000e+00 - val_loss: -167339312.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -168373200.0000 - accuracy: 0.0000e+00 - val_loss: -168019088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 248/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -169056576.0000 - accuracy: 0.0000e+00 - val_loss: -168699792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 249/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -169739824.0000 - accuracy: 0.0000e+00 - val_loss: -169380144.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 250/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -170423168.0000 - accuracy: 0.0000e+00 - val_loss: -170061088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -171106384.0000 - accuracy: 0.0000e+00 - val_loss: -170741184.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -171790320.0000 - accuracy: 0.0000e+00 - val_loss: -171423232.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -172474304.0000 - accuracy: 0.0000e+00 - val_loss: -172103648.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -173157840.0000 - accuracy: 0.0000e+00 - val_loss: -172784352.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -173841296.0000 - accuracy: 0.0000e+00 - val_loss: -173464960.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 256/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -174524624.0000 - accuracy: 0.0000e+00 - val_loss: -174145168.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -175208480.0000 - accuracy: 0.0000e+00 - val_loss: -174826288.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -175892064.0000 - accuracy: 0.0000e+00 - val_loss: -175506912.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/500\n",
            "491/491 [==============================] - 0s 963us/step - loss: -176575072.0000 - accuracy: 0.0000e+00 - val_loss: -176187712.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -177258480.0000 - accuracy: 0.0000e+00 - val_loss: -176868480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -177942176.0000 - accuracy: 0.0000e+00 - val_loss: -177548560.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -178626000.0000 - accuracy: 0.0000e+00 - val_loss: -178229344.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 263/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -179309616.0000 - accuracy: 0.0000e+00 - val_loss: -178910352.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 264/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -179993056.0000 - accuracy: 0.0000e+00 - val_loss: -179591200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -180676368.0000 - accuracy: 0.0000e+00 - val_loss: -180271712.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 266/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -181359856.0000 - accuracy: 0.0000e+00 - val_loss: -180951680.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -182042896.0000 - accuracy: 0.0000e+00 - val_loss: -181632288.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -182726240.0000 - accuracy: 0.0000e+00 - val_loss: -182313072.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/500\n",
            "491/491 [==============================] - 0s 973us/step - loss: -183409552.0000 - accuracy: 0.0000e+00 - val_loss: -182993456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 270/500\n",
            "491/491 [==============================] - 0s 966us/step - loss: -184092576.0000 - accuracy: 0.0000e+00 - val_loss: -183673328.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 271/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -184776144.0000 - accuracy: 0.0000e+00 - val_loss: -184354816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 272/500\n",
            "491/491 [==============================] - 0s 989us/step - loss: -185459184.0000 - accuracy: 0.0000e+00 - val_loss: -185034384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -186142256.0000 - accuracy: 0.0000e+00 - val_loss: -185714784.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 274/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -186825360.0000 - accuracy: 0.0000e+00 - val_loss: -186395472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 275/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -187508624.0000 - accuracy: 0.0000e+00 - val_loss: -187075680.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -188192576.0000 - accuracy: 0.0000e+00 - val_loss: -187756896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/500\n",
            "491/491 [==============================] - 0s 992us/step - loss: -188876128.0000 - accuracy: 0.0000e+00 - val_loss: -188437456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -189559056.0000 - accuracy: 0.0000e+00 - val_loss: -189117856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -190242752.0000 - accuracy: 0.0000e+00 - val_loss: -189799024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -190926880.0000 - accuracy: 0.0000e+00 - val_loss: -190480096.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -191610528.0000 - accuracy: 0.0000e+00 - val_loss: -191160912.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -192293632.0000 - accuracy: 0.0000e+00 - val_loss: -191840400.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -192977216.0000 - accuracy: 0.0000e+00 - val_loss: -192522208.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 284/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -193660592.0000 - accuracy: 0.0000e+00 - val_loss: -193202272.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -194343840.0000 - accuracy: 0.0000e+00 - val_loss: -193882864.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -195027440.0000 - accuracy: 0.0000e+00 - val_loss: -194563168.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -195710752.0000 - accuracy: 0.0000e+00 - val_loss: -195243472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -196394288.0000 - accuracy: 0.0000e+00 - val_loss: -195924720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -197077872.0000 - accuracy: 0.0000e+00 - val_loss: -196605312.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -197761280.0000 - accuracy: 0.0000e+00 - val_loss: -197285952.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -198444704.0000 - accuracy: 0.0000e+00 - val_loss: -197966672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 292/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -199128592.0000 - accuracy: 0.0000e+00 - val_loss: -198647840.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -199811840.0000 - accuracy: 0.0000e+00 - val_loss: -199328256.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -200495088.0000 - accuracy: 0.0000e+00 - val_loss: -200008976.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 295/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -201178272.0000 - accuracy: 0.0000e+00 - val_loss: -200688672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 296/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -201861712.0000 - accuracy: 0.0000e+00 - val_loss: -201369456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -202545152.0000 - accuracy: 0.0000e+00 - val_loss: -202050048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -203228688.0000 - accuracy: 0.0000e+00 - val_loss: -202730816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -203912224.0000 - accuracy: 0.0000e+00 - val_loss: -203411312.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -204595856.0000 - accuracy: 0.0000e+00 - val_loss: -204092640.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -205279168.0000 - accuracy: 0.0000e+00 - val_loss: -204773040.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 302/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -205962752.0000 - accuracy: 0.0000e+00 - val_loss: -205453600.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 303/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -206645952.0000 - accuracy: 0.0000e+00 - val_loss: -206134096.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 304/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -207329280.0000 - accuracy: 0.0000e+00 - val_loss: -206814480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 305/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -208012896.0000 - accuracy: 0.0000e+00 - val_loss: -207495568.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 306/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -208696512.0000 - accuracy: 0.0000e+00 - val_loss: -208176384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 307/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -209379072.0000 - accuracy: 0.0000e+00 - val_loss: -208855968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 308/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -210062720.0000 - accuracy: 0.0000e+00 - val_loss: -209537008.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 309/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -210746256.0000 - accuracy: 0.0000e+00 - val_loss: -210217264.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 310/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -211429552.0000 - accuracy: 0.0000e+00 - val_loss: -210898592.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 311/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -212113344.0000 - accuracy: 0.0000e+00 - val_loss: -211579216.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 312/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -212797120.0000 - accuracy: 0.0000e+00 - val_loss: -212259936.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 313/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -213480896.0000 - accuracy: 0.0000e+00 - val_loss: -212940720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 314/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -214164416.0000 - accuracy: 0.0000e+00 - val_loss: -213621280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 315/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -214848112.0000 - accuracy: 0.0000e+00 - val_loss: -214302784.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 316/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -215531328.0000 - accuracy: 0.0000e+00 - val_loss: -214982640.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 317/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -216214016.0000 - accuracy: 0.0000e+00 - val_loss: -215663504.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 318/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -216897632.0000 - accuracy: 0.0000e+00 - val_loss: -216343792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 319/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -217581008.0000 - accuracy: 0.0000e+00 - val_loss: -217024160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 320/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -218264768.0000 - accuracy: 0.0000e+00 - val_loss: -217705456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 321/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -218948640.0000 - accuracy: 0.0000e+00 - val_loss: -218385792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 322/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -219631648.0000 - accuracy: 0.0000e+00 - val_loss: -219065968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 323/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -220314800.0000 - accuracy: 0.0000e+00 - val_loss: -219746224.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 324/500\n",
            "491/491 [==============================] - 0s 997us/step - loss: -220997344.0000 - accuracy: 0.0000e+00 - val_loss: -220426560.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 325/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -221680800.0000 - accuracy: 0.0000e+00 - val_loss: -221106720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -222364400.0000 - accuracy: 0.0000e+00 - val_loss: -221787824.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -223048096.0000 - accuracy: 0.0000e+00 - val_loss: -222468400.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -223731712.0000 - accuracy: 0.0000e+00 - val_loss: -223149376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 329/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -224414976.0000 - accuracy: 0.0000e+00 - val_loss: -223829632.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 330/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -225097568.0000 - accuracy: 0.0000e+00 - val_loss: -224509808.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 331/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -225780880.0000 - accuracy: 0.0000e+00 - val_loss: -225190048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 332/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -226464528.0000 - accuracy: 0.0000e+00 - val_loss: -225870656.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 333/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -227148128.0000 - accuracy: 0.0000e+00 - val_loss: -226551984.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 334/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -227831712.0000 - accuracy: 0.0000e+00 - val_loss: -227232224.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 335/500\n",
            "491/491 [==============================] - 0s 979us/step - loss: -228514192.0000 - accuracy: 0.0000e+00 - val_loss: -227911824.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 336/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -229197040.0000 - accuracy: 0.0000e+00 - val_loss: -228591952.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 337/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -229880304.0000 - accuracy: 0.0000e+00 - val_loss: -229272560.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 338/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -230563696.0000 - accuracy: 0.0000e+00 - val_loss: -229952848.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 339/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -231247136.0000 - accuracy: 0.0000e+00 - val_loss: -230633424.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 340/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -231930464.0000 - accuracy: 0.0000e+00 - val_loss: -231314320.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 341/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -232614080.0000 - accuracy: 0.0000e+00 - val_loss: -231995024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 342/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -233296672.0000 - accuracy: 0.0000e+00 - val_loss: -232674720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 343/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -233979408.0000 - accuracy: 0.0000e+00 - val_loss: -233355104.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 344/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -234662816.0000 - accuracy: 0.0000e+00 - val_loss: -234035376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 345/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -235345872.0000 - accuracy: 0.0000e+00 - val_loss: -234715392.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 346/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -236029456.0000 - accuracy: 0.0000e+00 - val_loss: -235396352.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 347/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -236713024.0000 - accuracy: 0.0000e+00 - val_loss: -236076848.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 348/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -237396048.0000 - accuracy: 0.0000e+00 - val_loss: -236756592.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 349/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -238078816.0000 - accuracy: 0.0000e+00 - val_loss: -237437280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 350/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -238761872.0000 - accuracy: 0.0000e+00 - val_loss: -238117696.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 351/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -239444560.0000 - accuracy: 0.0000e+00 - val_loss: -238797184.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 352/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -240127968.0000 - accuracy: 0.0000e+00 - val_loss: -239478288.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 353/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -240811600.0000 - accuracy: 0.0000e+00 - val_loss: -240159184.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 354/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -241495008.0000 - accuracy: 0.0000e+00 - val_loss: -240839760.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 355/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -242178592.0000 - accuracy: 0.0000e+00 - val_loss: -241519744.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 356/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -242861568.0000 - accuracy: 0.0000e+00 - val_loss: -242200544.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 357/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -243545568.0000 - accuracy: 0.0000e+00 - val_loss: -242881968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 358/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -244229040.0000 - accuracy: 0.0000e+00 - val_loss: -243562496.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 359/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -244912880.0000 - accuracy: 0.0000e+00 - val_loss: -244243440.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 360/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -245596528.0000 - accuracy: 0.0000e+00 - val_loss: -244924144.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 361/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -246280416.0000 - accuracy: 0.0000e+00 - val_loss: -245605616.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 362/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -246964016.0000 - accuracy: 0.0000e+00 - val_loss: -246285840.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 363/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -247647248.0000 - accuracy: 0.0000e+00 - val_loss: -246966048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 364/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -248331024.0000 - accuracy: 0.0000e+00 - val_loss: -247646752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 365/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -249014176.0000 - accuracy: 0.0000e+00 - val_loss: -248327376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 366/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -249696992.0000 - accuracy: 0.0000e+00 - val_loss: -249007328.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 367/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -250380064.0000 - accuracy: 0.0000e+00 - val_loss: -249687808.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 368/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -251063984.0000 - accuracy: 0.0000e+00 - val_loss: -250368400.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 369/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -251747536.0000 - accuracy: 0.0000e+00 - val_loss: -251049584.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 370/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -252430704.0000 - accuracy: 0.0000e+00 - val_loss: -251730016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 371/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -253113920.0000 - accuracy: 0.0000e+00 - val_loss: -252410288.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 372/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -253796912.0000 - accuracy: 0.0000e+00 - val_loss: -253090336.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 373/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -254479568.0000 - accuracy: 0.0000e+00 - val_loss: -253770496.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 374/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -255162560.0000 - accuracy: 0.0000e+00 - val_loss: -254450400.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 375/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -255845568.0000 - accuracy: 0.0000e+00 - val_loss: -255130672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 376/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -256529264.0000 - accuracy: 0.0000e+00 - val_loss: -255811600.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 377/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -257212720.0000 - accuracy: 0.0000e+00 - val_loss: -256492576.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 378/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -257896400.0000 - accuracy: 0.0000e+00 - val_loss: -257173808.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 379/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -258579888.0000 - accuracy: 0.0000e+00 - val_loss: -257853504.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 380/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -259262640.0000 - accuracy: 0.0000e+00 - val_loss: -258533360.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 381/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -259946448.0000 - accuracy: 0.0000e+00 - val_loss: -259214768.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 382/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -260630448.0000 - accuracy: 0.0000e+00 - val_loss: -259896160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 383/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -261314096.0000 - accuracy: 0.0000e+00 - val_loss: -260576384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 384/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -261997280.0000 - accuracy: 0.0000e+00 - val_loss: -261257040.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 385/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -262680560.0000 - accuracy: 0.0000e+00 - val_loss: -261937248.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 386/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -263364272.0000 - accuracy: 0.0000e+00 - val_loss: -262618304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 387/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -264047312.0000 - accuracy: 0.0000e+00 - val_loss: -263298672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 388/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -264730800.0000 - accuracy: 0.0000e+00 - val_loss: -263979392.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 389/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -265414128.0000 - accuracy: 0.0000e+00 - val_loss: -264659616.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 390/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -266097600.0000 - accuracy: 0.0000e+00 - val_loss: -265340752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 391/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -266781440.0000 - accuracy: 0.0000e+00 - val_loss: -266021840.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 392/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -267464752.0000 - accuracy: 0.0000e+00 - val_loss: -266702368.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 393/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -268148112.0000 - accuracy: 0.0000e+00 - val_loss: -267382384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 394/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -268831712.0000 - accuracy: 0.0000e+00 - val_loss: -268063296.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 395/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -269514592.0000 - accuracy: 0.0000e+00 - val_loss: -268742976.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 396/500\n",
            "491/491 [==============================] - 0s 988us/step - loss: -270198272.0000 - accuracy: 0.0000e+00 - val_loss: -269424000.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 397/500\n",
            "491/491 [==============================] - 0s 987us/step - loss: -270882208.0000 - accuracy: 0.0000e+00 - val_loss: -270104768.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 398/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -271565248.0000 - accuracy: 0.0000e+00 - val_loss: -270785344.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 399/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -272248640.0000 - accuracy: 0.0000e+00 - val_loss: -271466464.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 400/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -272932128.0000 - accuracy: 0.0000e+00 - val_loss: -272146432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 401/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -273615712.0000 - accuracy: 0.0000e+00 - val_loss: -272827552.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 402/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -274299360.0000 - accuracy: 0.0000e+00 - val_loss: -273508480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 403/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -274982976.0000 - accuracy: 0.0000e+00 - val_loss: -274189504.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 404/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -275666464.0000 - accuracy: 0.0000e+00 - val_loss: -274870272.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 405/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -276350528.0000 - accuracy: 0.0000e+00 - val_loss: -275550912.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 406/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -277034112.0000 - accuracy: 0.0000e+00 - val_loss: -276232128.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 407/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -277716800.0000 - accuracy: 0.0000e+00 - val_loss: -276911648.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 408/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -278400064.0000 - accuracy: 0.0000e+00 - val_loss: -277592096.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 409/500\n",
            "491/491 [==============================] - 0s 996us/step - loss: -279083264.0000 - accuracy: 0.0000e+00 - val_loss: -278272512.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 410/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -279766688.0000 - accuracy: 0.0000e+00 - val_loss: -278953024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 411/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -280449792.0000 - accuracy: 0.0000e+00 - val_loss: -279633632.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 412/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -281133312.0000 - accuracy: 0.0000e+00 - val_loss: -280314080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 413/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -281817344.0000 - accuracy: 0.0000e+00 - val_loss: -280995392.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 414/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -282500544.0000 - accuracy: 0.0000e+00 - val_loss: -281676192.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 415/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -283184256.0000 - accuracy: 0.0000e+00 - val_loss: -282356448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 416/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -283867968.0000 - accuracy: 0.0000e+00 - val_loss: -283037120.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 417/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -284551168.0000 - accuracy: 0.0000e+00 - val_loss: -283717856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 418/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -285234368.0000 - accuracy: 0.0000e+00 - val_loss: -284398016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 419/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -285917152.0000 - accuracy: 0.0000e+00 - val_loss: -285077984.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 420/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -286600448.0000 - accuracy: 0.0000e+00 - val_loss: -285759008.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 421/500\n",
            "491/491 [==============================] - 0s 987us/step - loss: -287284384.0000 - accuracy: 0.0000e+00 - val_loss: -286440192.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 422/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -287967872.0000 - accuracy: 0.0000e+00 - val_loss: -287120512.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 423/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -288651680.0000 - accuracy: 0.0000e+00 - val_loss: -287801600.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 424/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -289335328.0000 - accuracy: 0.0000e+00 - val_loss: -288482368.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 425/500\n",
            "491/491 [==============================] - 0s 977us/step - loss: -290019008.0000 - accuracy: 0.0000e+00 - val_loss: -289163616.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 426/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -290702432.0000 - accuracy: 0.0000e+00 - val_loss: -289843456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 427/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -291385312.0000 - accuracy: 0.0000e+00 - val_loss: -290523488.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 428/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -292068160.0000 - accuracy: 0.0000e+00 - val_loss: -291204064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 429/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -292752000.0000 - accuracy: 0.0000e+00 - val_loss: -291885440.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 430/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -293436000.0000 - accuracy: 0.0000e+00 - val_loss: -292566016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 431/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -294119744.0000 - accuracy: 0.0000e+00 - val_loss: -293247168.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 432/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -294802976.0000 - accuracy: 0.0000e+00 - val_loss: -293927392.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 433/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -295486400.0000 - accuracy: 0.0000e+00 - val_loss: -294608704.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 434/500\n",
            "491/491 [==============================] - 0s 991us/step - loss: -296169984.0000 - accuracy: 0.0000e+00 - val_loss: -295289408.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 435/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -296854112.0000 - accuracy: 0.0000e+00 - val_loss: -295970016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 436/500\n",
            "491/491 [==============================] - 0s 982us/step - loss: -297537568.0000 - accuracy: 0.0000e+00 - val_loss: -296650976.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 437/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -298221408.0000 - accuracy: 0.0000e+00 - val_loss: -297332032.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 438/500\n",
            "491/491 [==============================] - 0s 991us/step - loss: -298905088.0000 - accuracy: 0.0000e+00 - val_loss: -298012800.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 439/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -299588480.0000 - accuracy: 0.0000e+00 - val_loss: -298693280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 440/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -300271872.0000 - accuracy: 0.0000e+00 - val_loss: -299373888.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 441/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -300955616.0000 - accuracy: 0.0000e+00 - val_loss: -300054400.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 442/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -301638976.0000 - accuracy: 0.0000e+00 - val_loss: -300735616.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 443/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -302322560.0000 - accuracy: 0.0000e+00 - val_loss: -301416064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 444/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -303005792.0000 - accuracy: 0.0000e+00 - val_loss: -302096448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 445/500\n",
            "491/491 [==============================] - 0s 994us/step - loss: -303689312.0000 - accuracy: 0.0000e+00 - val_loss: -302777376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 446/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -304373312.0000 - accuracy: 0.0000e+00 - val_loss: -303458624.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 447/500\n",
            "491/491 [==============================] - 0s 995us/step - loss: -305057344.0000 - accuracy: 0.0000e+00 - val_loss: -304138464.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 448/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -305740832.0000 - accuracy: 0.0000e+00 - val_loss: -304820160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 449/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -306424032.0000 - accuracy: 0.0000e+00 - val_loss: -305500256.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 450/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -307107200.0000 - accuracy: 0.0000e+00 - val_loss: -306180768.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 451/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -307789728.0000 - accuracy: 0.0000e+00 - val_loss: -306860896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 452/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -308472832.0000 - accuracy: 0.0000e+00 - val_loss: -307540992.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 453/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -309156832.0000 - accuracy: 0.0000e+00 - val_loss: -308222208.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 454/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -309840224.0000 - accuracy: 0.0000e+00 - val_loss: -308902816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 455/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -310523456.0000 - accuracy: 0.0000e+00 - val_loss: -309582592.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 456/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -311206784.0000 - accuracy: 0.0000e+00 - val_loss: -310263264.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 457/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -311890656.0000 - accuracy: 0.0000e+00 - val_loss: -310944736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 458/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -312574112.0000 - accuracy: 0.0000e+00 - val_loss: -311624992.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 459/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -313257216.0000 - accuracy: 0.0000e+00 - val_loss: -312305568.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 460/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -313940736.0000 - accuracy: 0.0000e+00 - val_loss: -312986272.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 461/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -314624736.0000 - accuracy: 0.0000e+00 - val_loss: -313667520.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 462/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -315308192.0000 - accuracy: 0.0000e+00 - val_loss: -314348256.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 463/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -315991488.0000 - accuracy: 0.0000e+00 - val_loss: -315028448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 464/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -316675520.0000 - accuracy: 0.0000e+00 - val_loss: -315709280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 465/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -317358368.0000 - accuracy: 0.0000e+00 - val_loss: -316389504.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 466/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -318041632.0000 - accuracy: 0.0000e+00 - val_loss: -317070432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 467/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -318725216.0000 - accuracy: 0.0000e+00 - val_loss: -317750720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 468/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -319408320.0000 - accuracy: 0.0000e+00 - val_loss: -318431392.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 469/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -320091488.0000 - accuracy: 0.0000e+00 - val_loss: -319112224.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 470/500\n",
            "491/491 [==============================] - 0s 991us/step - loss: -320774560.0000 - accuracy: 0.0000e+00 - val_loss: -319791808.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 471/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -321457504.0000 - accuracy: 0.0000e+00 - val_loss: -320471808.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 472/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -322140864.0000 - accuracy: 0.0000e+00 - val_loss: -321152384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 473/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -322824704.0000 - accuracy: 0.0000e+00 - val_loss: -321833760.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 474/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -323508032.0000 - accuracy: 0.0000e+00 - val_loss: -322513888.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 475/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -324191584.0000 - accuracy: 0.0000e+00 - val_loss: -323194752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 476/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -324875232.0000 - accuracy: 0.0000e+00 - val_loss: -323875040.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 477/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -325558624.0000 - accuracy: 0.0000e+00 - val_loss: -324555456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 478/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -326241408.0000 - accuracy: 0.0000e+00 - val_loss: -325236064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 479/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -326925024.0000 - accuracy: 0.0000e+00 - val_loss: -325916768.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 480/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -327608576.0000 - accuracy: 0.0000e+00 - val_loss: -326597440.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 481/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -328291904.0000 - accuracy: 0.0000e+00 - val_loss: -327278336.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 482/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -328975296.0000 - accuracy: 0.0000e+00 - val_loss: -327958624.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 483/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -329659424.0000 - accuracy: 0.0000e+00 - val_loss: -328640448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 484/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -330342880.0000 - accuracy: 0.0000e+00 - val_loss: -329321280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 485/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -331025760.0000 - accuracy: 0.0000e+00 - val_loss: -330000480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 486/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -331708672.0000 - accuracy: 0.0000e+00 - val_loss: -330680480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 487/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -332391680.0000 - accuracy: 0.0000e+00 - val_loss: -331361504.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 488/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -333075232.0000 - accuracy: 0.0000e+00 - val_loss: -332042016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 489/500\n",
            "491/491 [==============================] - 0s 1ms/step - loss: -333758112.0000 - accuracy: 0.0000e+00 - val_loss: -332721664.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 490/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -334441760.0000 - accuracy: 0.0000e+00 - val_loss: -333402624.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 491/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -335125280.0000 - accuracy: 0.0000e+00 - val_loss: -334083872.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 492/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -335808896.0000 - accuracy: 0.0000e+00 - val_loss: -334764672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 493/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -336492320.0000 - accuracy: 0.0000e+00 - val_loss: -335445344.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 494/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -337175808.0000 - accuracy: 0.0000e+00 - val_loss: -336124960.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 495/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -337859232.0000 - accuracy: 0.0000e+00 - val_loss: -336805792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 496/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -338543008.0000 - accuracy: 0.0000e+00 - val_loss: -337487232.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 497/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -339225952.0000 - accuracy: 0.0000e+00 - val_loss: -338167328.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 498/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -339909216.0000 - accuracy: 0.0000e+00 - val_loss: -338847488.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 499/500\n",
            "491/491 [==============================] - 0s 989us/step - loss: -340592960.0000 - accuracy: 0.0000e+00 - val_loss: -339529088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 500/500\n",
            "491/491 [==============================] - 1s 1ms/step - loss: -341276608.0000 - accuracy: 0.0000e+00 - val_loss: -340209696.0000 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "# Define the neural network architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(3,)),  # Input layer with 2 features\n",
        "#    tf.keras.layers.Dense(3, activation='sigmoid'),  # Hidden layer with 4 neurons and ReLU activation\n",
        "#    tf.keras.layers.Dense(3, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "\n",
        "num_iterations=1\n",
        "\n",
        "\n",
        "history, model = train_NN(X1_train1,y1_train1,X1_validation,y1_validation,model,num_iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Extract accuracy values from the training history\n",
        "training_accuracy_per_epoch = history.history['loss']\n",
        "validation_accuracy_per_epoch = history.history['val_loss']\n",
        "\n",
        "  #loss_train, accuracy= model.evaluate(X1_train1, y1_train1)\n",
        "  #loss_train, accuracy= model.evaluate(X1_train, y1_train)\n",
        "\n",
        "  \n",
        "  # Plot the accuracy values\n",
        "plt.plot(training_accuracy_per_epoch, label='Training Accuracy')\n",
        "plt.plot(validation_accuracy_per_epoch, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
